{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nama</th>\n",
       "      <th>bintang</th>\n",
       "      <th>komentar</th>\n",
       "      <th>Waktu</th>\n",
       "      <th>Place name</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>final_text</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Satria Sihombing</td>\n",
       "      <td>5.0</td>\n",
       "      <td>the view is on ðŸ¤©ðŸ”¥ðŸ”¥</td>\n",
       "      <td>an hour</td>\n",
       "      <td>Bobocabin Baturraden Purwokerto</td>\n",
       "      <td>view nya menyala ðŸ¤©ðŸ”¥ðŸ”¥</td>\n",
       "      <td>the view i on</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>silas nainggolan</td>\n",
       "      <td>5.0</td>\n",
       "      <td>accommodation that is most united with nature....</td>\n",
       "      <td>an hour</td>\n",
       "      <td>Bobocabin Baturraden Purwokerto</td>\n",
       "      <td>penginapan yang paling menyatu dengan alam. ca...</td>\n",
       "      <td>accommodation that i most united with nature t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ari Setiawan</td>\n",
       "      <td>5.0</td>\n",
       "      <td>nice, new hotel with a high-tech feel, with ve...</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>Bobocabin Baturraden Purwokerto</td>\n",
       "      <td>bagus, hotel bernuasna baru yang berteknologi ...</td>\n",
       "      <td>nice new hotel with a hightech feel with very ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mutiara saragih</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>Bobocabin Baturraden Purwokerto</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hendro sebayang</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sok an exciting stay experience</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>Bobocabin Baturraden Purwokerto</td>\n",
       "      <td>sok an exciting stay experience</td>\n",
       "      <td>sok an exciting stay experience</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               nama  bintang  \\\n",
       "0  Satria Sihombing      5.0   \n",
       "1  silas nainggolan      5.0   \n",
       "2      Ari Setiawan      5.0   \n",
       "3   mutiara saragih      5.0   \n",
       "4   hendro sebayang      5.0   \n",
       "\n",
       "                                            komentar    Waktu  \\\n",
       "0                                 the view is on ðŸ¤©ðŸ”¥ðŸ”¥  an hour   \n",
       "1  accommodation that is most united with nature....  an hour   \n",
       "2  nice, new hotel with a high-tech feel, with ve...  2 hours   \n",
       "3                                               good  2 hours   \n",
       "4                    sok an exciting stay experience  2 hours   \n",
       "\n",
       "                        Place name  \\\n",
       "0  Bobocabin Baturraden Purwokerto   \n",
       "1  Bobocabin Baturraden Purwokerto   \n",
       "2  Bobocabin Baturraden Purwokerto   \n",
       "3  Bobocabin Baturraden Purwokerto   \n",
       "4  Bobocabin Baturraden Purwokerto   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                               view nya menyala ðŸ¤©ðŸ”¥ðŸ”¥   \n",
       "1  penginapan yang paling menyatu dengan alam. ca...   \n",
       "2  bagus, hotel bernuasna baru yang berteknologi ...   \n",
       "3                                               good   \n",
       "4                    sok an exciting stay experience   \n",
       "\n",
       "                                          final_text  review_id  \n",
       "0                                      the view i on          0  \n",
       "1  accommodation that i most united with nature t...          1  \n",
       "2  nice new hotel with a hightech feel with very ...          2  \n",
       "3                                               good          3  \n",
       "4                    sok an exciting stay experience          4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('combined_English_scrap_result.csv')\n",
    "df = pd.read_csv('final_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nama</th>\n",
       "      <th>bintang</th>\n",
       "      <th>komentar</th>\n",
       "      <th>Waktu</th>\n",
       "      <th>Place name</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>final_text</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>Tiara</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've been to Jakarta many times and stayed her...</td>\n",
       "      <td>4 months</td>\n",
       "      <td>Bobopod Pancoran Jakarta</td>\n",
       "      <td>berkali2 ke jakarta nginepnya di sini kalau la...</td>\n",
       "      <td>ive been to jakarta many time and stayed here ...</td>\n",
       "      <td>5649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nama  bintang                                           komentar  \\\n",
       "5626  Tiara      5.0  I've been to Jakarta many times and stayed her...   \n",
       "\n",
       "         Waktu                Place name  \\\n",
       "5626  4 months  Bobopod Pancoran Jakarta   \n",
       "\n",
       "                                             clean_text  \\\n",
       "5626  berkali2 ke jakarta nginepnya di sini kalau la...   \n",
       "\n",
       "                                             final_text  review_id  \n",
       "5626  ive been to jakarta many time and stayed here ...       5649  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.review_id == 5649]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nama          0\n",
       "bintang       0\n",
       "komentar      0\n",
       "Waktu         0\n",
       "Place name    0\n",
       "clean_text    0\n",
       "final_text    0\n",
       "review_id     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6751 entries, 0 to 6751\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   nama        6751 non-null   object \n",
      " 1   bintang     6751 non-null   float64\n",
      " 2   komentar    6751 non-null   object \n",
      " 3   Waktu       6751 non-null   object \n",
      " 4   Place name  6751 non-null   object \n",
      " 5   clean_text  6751 non-null   object \n",
      " 6   final_text  6751 non-null   object \n",
      " 7   review_id   6751 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 474.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Harun A\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Processing reviews:   9%|â–‰         | 612/6751 [18:57<3:10:06,  1.86s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m df_ \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Process the DataFrame\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m processed_df \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_reviews\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinal_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Display the processed DataFrame\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(processed_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[15], line 55\u001b[0m, in \u001b[0;36mprocess_reviews\u001b[1;34m(df, id_column, text_column)\u001b[0m\n\u001b[0;32m     53\u001b[0m aspects \u001b[38;5;241m=\u001b[39m extract_aspects(truncated_sentence)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m aspect \u001b[38;5;129;01min\u001b[39;00m aspects:\n\u001b[1;32m---> 55\u001b[0m     sentiment_scores \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_aspect_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtruncated_sentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     highest_sentiment_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(sentiment_scores, key\u001b[38;5;241m=\u001b[39msentiment_scores\u001b[38;5;241m.\u001b[39mget)\n\u001b[0;32m     57\u001b[0m     highest_sentiment_score \u001b[38;5;241m=\u001b[39m sentiment_scores[highest_sentiment_label]\n",
      "Cell \u001b[1;32mIn[15], line 34\u001b[0m, in \u001b[0;36manalyze_aspect_sentiment\u001b[1;34m(sentence, aspect)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_aspect_sentiment\u001b[39m(sentence, aspect):\n\u001b[0;32m     33\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m absa_tokenizer(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[CLS] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [SEP] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maspect\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [SEP]\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m absa_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     35\u001b[0m     probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m     probs \u001b[38;5;241m=\u001b[39m probs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:1297\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1297\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m encoder_layer \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1309\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(encoder_layer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:1063\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m   1055\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1056\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1057\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1060\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1061\u001b[0m )\n\u001b[1;32m-> 1063\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1070\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:507\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[1;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[0;32m    497\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    498\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    499\u001b[0m         next_kv,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m         output_attentions,\n\u001b[0;32m    505\u001b[0m     )\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 507\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    517\u001b[0m     output_states, att_m \u001b[38;5;241m=\u001b[39m output_states\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:355\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[1;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    348\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    353\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m ):\n\u001b[1;32m--> 355\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    364\u001b[0m         attention_output, att_matrix \u001b[38;5;241m=\u001b[39m attention_output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:298\u001b[0m, in \u001b[0;36mDebertaV2Attention.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m     query_states \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m--> 298\u001b[0m attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (attention_output, att_matrix)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:263\u001b[0m, in \u001b[0;36mDebertaV2SelfOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states, input_tensor):\n\u001b[1;32m--> 263\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    265\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load ABSA model\n",
    "absa_tokenizer = AutoTokenizer.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "absa_model = AutoModelForSequenceClassification.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "\n",
    "# Load traditional Sentiment Analysis model\n",
    "sentiment_model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_model = pipeline(\"sentiment-analysis\", model=sentiment_model_path, tokenizer=sentiment_model_path)\n",
    "\n",
    "# Function to extract aspects using dependency parsing\n",
    "def extract_aspects(review):\n",
    "    doc = nlp(review)\n",
    "    aspects = set()\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"nsubj\" and token.pos_ == \"NOUN\":\n",
    "            aspects.add(token.text.lower())\n",
    "        elif token.dep_ == \"amod\" and token.head.pos_ == \"NOUN\":\n",
    "            aspects.add(token.head.text.lower())\n",
    "    return list(aspects)\n",
    "\n",
    "# Function to perform ABSA\n",
    "def analyze_aspect_sentiment(sentence, aspect):\n",
    "    inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "    outputs = absa_model(**inputs)\n",
    "    probs = F.softmax(outputs.logits, dim=1)\n",
    "    probs = probs.detach().numpy()[0]\n",
    "    return {label: prob for label, prob in zip([\"negative\", \"neutral\", \"positive\"], probs)}\n",
    "\n",
    "# Truncate long sentences to avoid exceeding the maximum token length\n",
    "def truncate_sentence(sentence, max_length=512):\n",
    "    tokens = sentence.split()\n",
    "    if len(tokens) > max_length:\n",
    "        return ' '.join(tokens[:max_length])\n",
    "    return sentence\n",
    "\n",
    "# Process the DataFrame\n",
    "def process_reviews(df, id_column, text_column):\n",
    "    results = []\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing reviews\"):\n",
    "        review_id = row[id_column]\n",
    "        sentence = row[text_column]\n",
    "        truncated_sentence = truncate_sentence(sentence)\n",
    "        aspects = extract_aspects(truncated_sentence)\n",
    "        for aspect in aspects:\n",
    "            sentiment_scores = analyze_aspect_sentiment(truncated_sentence, aspect)\n",
    "            highest_sentiment_label = max(sentiment_scores, key=sentiment_scores.get)\n",
    "            highest_sentiment_score = sentiment_scores[highest_sentiment_label]\n",
    "            results.append({\n",
    "                'review_id': review_id,\n",
    "                'aspect': aspect,\n",
    "                'sentiment_label': highest_sentiment_label,\n",
    "                'sentiment_score': highest_sentiment_score\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "df_ = df.copy()\n",
    "\n",
    "# Process the DataFrame\n",
    "processed_df = process_reviews(df_, 'review_id', 'final_text')\n",
    "\n",
    "# Display the processed DataFrame\n",
    "print(processed_df.head())\n",
    "\n",
    "# Save the processed DataFrame to CSV for further analysis\n",
    "processed_df.to_csv('aspect_sentiment_analysis.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[369]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhammad Harun A\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review   aspect sentiment_label  \\\n",
      "0                                 the view is on ðŸ¤©ðŸ”¥ðŸ”¥     View        negative   \n",
      "1                                 the view is on ðŸ¤©ðŸ”¥ðŸ”¥     View         neutral   \n",
      "2                                 the view is on ðŸ¤©ðŸ”¥ðŸ”¥     View        positive   \n",
      "3  nice, new hotel with a high-tech feel, with ve...  Service        negative   \n",
      "4  nice, new hotel with a high-tech feel, with ve...  Service         neutral   \n",
      "\n",
      "   sentiment_score  \n",
      "0         0.010251  \n",
      "1         0.911546  \n",
      "2         0.078204  \n",
      "3         0.000552  \n",
      "4         0.001676  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load ABSA model\n",
    "absa_tokenizer = AutoTokenizer.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "absa_model = AutoModelForSequenceClassification.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "\n",
    "# Load traditional Sentiment Analysis model\n",
    "sentiment_model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_model = pipeline(\"sentiment-analysis\", model=sentiment_model_path, tokenizer=sentiment_model_path)\n",
    "\n",
    "# Predefined aspects\n",
    "ASPECTS = ['Room', 'Location', 'Service', 'Cleanliness', 'Price']\n",
    "\n",
    "# Truncate long sentences to avoid exceeding the maximum token length\n",
    "def truncate_sentence(sentence, max_length=512):\n",
    "    tokens = sentence.split()\n",
    "    if len(tokens) > max_length:\n",
    "        return ' '.join(tokens[:max_length])\n",
    "    return sentence\n",
    "\n",
    "# Function to perform ABSA\n",
    "def analyze_aspect_sentiment(sentence, aspect):\n",
    "    inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "    outputs = absa_model(**inputs)\n",
    "    probs = F.softmax(outputs.logits, dim=1)\n",
    "    probs = probs.detach().numpy()[0]\n",
    "    return {label: prob for label, prob in zip([\"negative\", \"neutral\", \"positive\"], probs)}\n",
    "\n",
    "# Check if aspect is present in the sentence\n",
    "def is_aspect_present(sentence, aspect):\n",
    "    doc = nlp(sentence)\n",
    "    return any(token.text.lower() == aspect.lower() for token in doc)\n",
    "\n",
    "# Process the DataFrame\n",
    "def process_reviews(df, text_column):\n",
    "    results = []\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row[text_column]\n",
    "        truncated_sentence = truncate_sentence(sentence)\n",
    "        for aspect in ASPECTS:\n",
    "            if is_aspect_present(sentence, aspect):\n",
    "                sentiment_scores = analyze_aspect_sentiment(truncated_sentence, aspect)\n",
    "                for label, score in sentiment_scores.items():\n",
    "                    results.append({\n",
    "                        'review': sentence,\n",
    "                        'aspect': aspect,\n",
    "                        'sentiment_label': label,\n",
    "                        'sentiment_score': score\n",
    "                    })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "df_ = df.iloc[:5]\n",
    "\n",
    "# Process the DataFrame\n",
    "processed_df = process_reviews(df_, 'komentar')\n",
    "\n",
    "# Display the processed DataFrame\n",
    "print(processed_df.head())\n",
    "\n",
    "# Save the processed DataFrame to CSV for further analysis\n",
    "processed_df.to_csv('aspect_sentiment_analysis.csv', index=False)\n",
    "\n",
    "# Visualization\n",
    "def visualize_aspect_sentiment(df):\n",
    "    # Pivot the data for visualization\n",
    "    pivot_df = df.pivot_table(values='sentiment_score', index='aspect', columns='sentiment_label', aggfunc='mean').fillna(0)\n",
    "\n",
    "    # Normalize the scores to avoid bias\n",
    "    pivot_df = pivot_df.div(pivot_df.sum(axis=1), axis=0)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(pivot_df, annot=True, cmap='coolwarm', cbar_kws={'label': 'Normalized Sentiment Score'})\n",
    "    plt.title('Aspect-Based Sentiment Analysis')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Aspect')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the processed DataFrame\n",
    "visualize_aspect_sentiment(processed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Can't choose a room, there is no water refill in best cabins no. 11 and 34\n",
      "\n",
      "Sentiment of aspect 'Room' is:\n",
      "Label negative: 0.05030994117259979\n",
      "Label neutral: 0.947429358959198\n",
      "Label positive: 0.00226070755161345\n",
      "\n",
      "Sentiment of aspect 'Location' is:\n",
      "Label negative: 0.5756540894508362\n",
      "Label neutral: 0.397415429353714\n",
      "Label positive: 0.026930460706353188\n",
      "\n",
      "Sentiment of aspect 'Service' is:\n",
      "Label negative: 0.8695281744003296\n",
      "Label neutral: 0.09458485245704651\n",
      "Label positive: 0.03588702529668808\n",
      "\n",
      "Sentiment of aspect 'Cleanliness' is:\n",
      "Label negative: 0.9051947593688965\n",
      "Label neutral: 0.03938903287053108\n",
      "Label positive: 0.05541619658470154\n",
      "\n",
      "Sentiment of aspect 'Price' is:\n",
      "Label negative: 0.5805014371871948\n",
      "Label neutral: 0.37701931595802307\n",
      "Label positive: 0.0424792654812336\n",
      "\n",
      "Sentiment of aspect 'food' is:\n",
      "Label negative: 0.924163281917572\n",
      "Label neutral: 0.06482042372226715\n",
      "Label positive: 0.011016339994966984\n",
      "\n",
      "Overall sentiment: negative with score 0.6162237524986267\n"
     ]
    }
   ],
   "source": [
    "sentence = \"rooms, good facilities, quiet, away from the crowds, very beautiful waterfall, don't forget breakfast, really delicious, warlok damar dinner, recommended is delicious, everyone must try ordering directly, staff orders food\"\n",
    "# sentence = translated\n",
    "print(f\"Sentence: {sentence}\")\n",
    "print()\n",
    "\n",
    "# ABSA of \"food\"\n",
    "aspect = \"Room\"\n",
    "inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "outputs = absa_model(**inputs)\n",
    "probs = F.softmax(outputs.logits, dim=1)\n",
    "probs = probs.detach().numpy()[0]\n",
    "print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "  print(f\"Label {label}: {prob}\")\n",
    "print()\n",
    "\n",
    "# ABSA of \"Location\"\n",
    "aspect = \"Location\"\n",
    "inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "outputs = absa_model(**inputs)\n",
    "probs = F.softmax(outputs.logits, dim=1)\n",
    "probs = probs.detach().numpy()[0]\n",
    "print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "  print(f\"Label {label}: {prob}\")\n",
    "print()\n",
    "\n",
    "# ABSA of \"service\"\n",
    "aspect = \"Service\"\n",
    "inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "outputs = absa_model(**inputs)\n",
    "probs = F.softmax(outputs.logits, dim=1)\n",
    "probs = probs.detach().numpy()[0]\n",
    "print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "  print(f\"Label {label}: {prob}\")\n",
    "print()\n",
    "\n",
    "# ABSA of \"Cleanliness\"\n",
    "aspect = \"Cleanliness\"\n",
    "inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "outputs = absa_model(**inputs)\n",
    "probs = F.softmax(outputs.logits, dim=1)\n",
    "probs = probs.detach().numpy()[0]\n",
    "print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "  print(f\"Label {label}: {prob}\")\n",
    "print()\n",
    "\n",
    "# ABSA of \"Price\"\n",
    "aspect = \"Price\"\n",
    "inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "outputs = absa_model(**inputs)\n",
    "probs = F.softmax(outputs.logits, dim=1)\n",
    "probs = probs.detach().numpy()[0]\n",
    "print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "  print(f\"Label {label}: {prob}\")\n",
    "print()\n",
    "\n",
    "# ABSA of \"Food\"\n",
    "aspect = \"food\"\n",
    "inputs = absa_tokenizer(f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "outputs = absa_model(**inputs)\n",
    "probs = F.softmax(outputs.logits, dim=1)\n",
    "probs = probs.detach().numpy()[0]\n",
    "print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "  print(f\"Label {label}: {prob}\")\n",
    "print()\n",
    "\n",
    "# Overall sentiment of the sentence\n",
    "sentiment = sentiment_model([sentence])[0]\n",
    "print(f\"Overall sentiment: {sentiment['label']} with score {sentiment['score']}\")\n",
    "# Overall sentiment: Negative with score 0.7706006765365601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
